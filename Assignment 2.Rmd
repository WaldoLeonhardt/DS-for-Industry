---
title: "STA5076Z Assignment 2: SONA Predict the President"
author: "Marike du Plessis (DPLMAR037), Waldo Leonhardt (LNHWAL001) and Francois Evert (EVRFRA002)"
date: "13 September 2018"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This is the second assignment for Data Science for Industry where the goal is to use as input the State of the Nation Address (SONA) speeches and achieve the following:

1.	Build a neural network classifier which can predict who was the president from any given sentence extracted from a speech.
2.	Assess the out-of-sample performance of the classifier.
3.	Conduct a descriptive analysis of the text in the speeches


## Load data

Start by extracting data out of the SONA files.
Build a data frame containing the filename, the speech text, president and year of speech.

```{r}
library(tidyverse)

# extract list of SONA files
# NOTE: that file name "2009_pre_elections_ Motlanthe.txt" has been corrected to remove the space before Motlanthe as this will cause issues later
#       when the president name needs to be assosiated with matrix entries
sona_files = list.files("data/")

# create empty data frame for SONA data
sona_data = data.frame(filename = as.character(), speech = as.character(), president = as.character())

# step through files and build sona_data
for(i in sona_files){
  this_file = paste0("data/", i)
  
  # extract president
  this_file_name = str_replace(i, ".txt", "") # remove .txt from file name
  
  this_president = str_sub(this_file_name, start = last(unlist(str_locate_all(this_file_name, "_")))+1, end = nchar(this_file_name))
  
  # extract speech text as single character string (can also read.table but the "seperator" causes problems)
  this_speech = readChar(this_file,
                         nchars = file.info(this_file)$size)
  
  # make data frame with metadata (filename contains year and pres) and speech
  this_sona = data.frame(filename = i, speech = this_speech, president = this_president, stringsAsFactors = FALSE)
  
  # add row to sona_data
  sona_data = rbind(sona_data, this_sona)
}

# add year to SONA data
sona_data$year = str_extract(sona_data$filename, "[0-9]{4}") # year is the first 4 numbers

head(sona_data)
```

Extract sentences

```{r}
library(tidytext)

# we want to predict sentences, so we need to first split into sentences
# use the speech attribute and replace with a sentence attribute, tokenized by sentences
sona_sentences = sona_data %>% unnest_tokens(sentence, speech, token = "sentences")

# convert to lower case
sona_sentences$sentence = str_to_lower(sona_sentences$sentence)

head(sona_sentences)
```

Extract words

```{r}
# add an ID variable for sentences
sona_sentences$sentence.id = rownames(sona_sentences) # use row number and assign to new ID variable

# use the sentence attribute and replace with a word attribute, tokenized by words
sona_words = sona_sentences %>% unnest_tokens(word, sentence, token = "words")

head(sona_words)
```

List the most frequent words used

```{r}
# view word frequencies
sona_words %>%
  count(word, sort = TRUE) %>%
  filter(rank(desc(n)) <= 30) # list top 30 ranked words
```

```{r}
# can also be done by the following
sona_words %>%
  group_by(word) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  head(30)
```

As expected, the most frequent words are stop-words. Let's remove those first.

```{r}
# remove stop-words
sona_words = sona_words %>%
  filter(!word %in% stop_words$word, str_detect(word, "[a-z]")) %>% # remove stop words
  #filter(!str_detect(word, "[[:punct:]]")) %>% # remove punctuation NOTE: this will remove all words containing any punctuation
  select(-filename)

head(sona_words, 30)
```

Look again at the words occuring the most

```{r}
# view word frequencies
sona_words %>%
  count(word, sort = TRUE) %>%
  filter(rank(desc(n)) <= 30) # list top 30 ranked words
```

Add count of words per sentance

```{r}
sona_words = sona_words %>%
  group_by(president, year, sentence.id, word) %>%
  summarise(count = n())

# list sentences with the most reoccuring words
sona_words %>%
  arrange(desc(count)) %>%
  head(30)
```

Reshape data in matrix form

```{r}
# build matrix of words per sentence.id
sona_matrix = sona_words %>%
  ungroup() %>% # remove grouping, otherwise complete and spread will use variables 'president' and 'year'
  select(sentence.id, word, count) %>%
  #complete(sentence.id, word) %>% 
  spread(key = word, value = count, fill = 0, convert = T) # use fill to replace NA's with 0

sona_matrix[1:10,1:20]
```

Clean matrix by moving the sentence.id into the row name, and adding the presidents name as a predictor variable.

```{r}
# create predicter vector of president names
predicter_presidents_name = sona_sentences[sona_sentences$sentence.id %in% sona_matrix$sentence.id,]$president

sona_rownames = sona_matrix$sentence.id

# remove sentence.id
sona_matrix = sona_matrix[,-1]

sona_colnames = colnames(sona_matrix)

# turn into a matrix
sona_matrix = as.matrix(sona_matrix)

# make sentence.id the row name
rownames(sona_matrix) = sona_rownames
colnames(sona_matrix) = sona_colnames

sona_matrix[1:10,1:20]
```

Confirm the size of our matrix

```{r}
dim(sona_matrix)
```

Confirm the number of presidents

```{r}
sona_words %>%
  group_by(president) %>%
  summarise(word.count = sum(count)) %>%
  mutate(word.percentage = round(word.count / sum(sona_words$count) * 100, 2)) %>%
  select(president, word.count, word.percentage) %>%
  arrange(word.count)
```

```{r}
#sona_sentences %>%
#  group_by(year, president) %>%
#  summarise(sentence.count = n()) %>%
#  arrange(year)

sona_sentences %>%
  group_by(president) %>%
  summarise(sentence.count = n()) %>%
  mutate(sentence.percentage = round(sentence.count / nrow(sona_sentences) * 100, 2)) %>%
  mutate(max.count = max(sentence.count)) %>%
  mutate(adjust.class.weight = round(max.count / sentence.count, 1)) %>%
  select(president, sentence.count, sentence.percentage, adjust.class.weight) %>%
  arrange(sentence.count)
```


## Feed-forward neural network

Create a basic feed-forward neural network using the keras package.

We will assess the accuracy of our model by using a train and test dataset.

Train data will be 80% of the explicit book ratings.
Test data will be the remaining 20%.

```{r}
library(keras)
set.seed(123)

# scale data
# sona_matrix = scale(sona_matrix) # NOTE: scaling did not improved model performance

# select training index
train.index = sample(1:nrow(sona_matrix), size = nrow(sona_matrix) * 0.8, replace = F)

# initiate model
model1 = keras_model_sequential()

input_shape = ncol(sona_matrix) # the number of destinct words
output_shape = 6 # the 6 presidents we want to predict

# convert presidents into numbers
# 0 = deKlerk
# 1 = Mandela
# 2 = Mbeki
# 3 = Motlanthe
# 4 = Zuma
# 5 = Ramaphosa
predicter_presidents_id = (0:5)[ match(predicter_presidents_name, c("deKlerk", "Mandela", "Mbeki", "Motlanthe", "Zuma", "Ramaphosa") ) ] 

x_train = sona_matrix[train.index, ]
x_test = sona_matrix[-train.index, ]

y_train = predicter_presidents_id[train.index]
y_test = predicter_presidents_id[-train.index]

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# define model layers
model1 %>% 
  layer_dense(units = 6517,                # number of neurons in 1st hidden layer, use 2/3 of (input_shape + output_shape)
  input_shape = input_shape) %>%           # dimension of input array
  layer_activation('relu') %>%             # use a rectified linear unit as an activation function in the hidden layer
  layer_dense(units = output_shape) %>%    # adds an output layer to the network
  layer_activation('softmax')              # use softmax activation function in the output layer

# compile model
model1 %>% compile(
  optimizer = 'adam',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy')
)

# fit model
model1 %>%
  fit(x = x_train,   # for the x input we exclude columns 1=sentence.id, and 9771=predicter.presidents.name
      y = y_train,
      epochs = 50,
      batch_size = 32,
      validation_data = list(x_test, y_test)) %>%
  plot()
```


Save model

```{r}
save_model_hdf5(model1, "Waldo_SONA_model1.h5") #save model to use later on
save_model_weights_hdf5(model1, "Waldo_SONA_model1_weights.h5") #save model weights to use later on
```


Compare train and test accuracy

```{r}
cat("Train classification success rate = ", mean(model1$predict_classes(x_train) == predicter_presidents_id[train.index]), "\n")
cat("Test classification success rate = ", mean(model1$predict_classes(x_test) == predicter_presidents_id[-train.index]))
```

From the above result we can see that the model is overfitting as the train accuracy is double that of the test accuracy.

```{r}
# initiate model
model2 = keras_model_sequential()

# define model layers
model2 %>% 
  layer_dense(units = 6517,                     # number of neurons in 1st hidden layer, use 2/3 of (input_shape + output_shape)
              activation = 'relu',              # use a rectified linear unit as an activation function in 1st hidden layer
              input_shape = input_shape) %>%    # dimension of input array
  layer_dropout(rate = 0.3) %>%                 # add dropout with rate 30%
  
  layer_dense(units = 3258,                     # number of neurons in 2nd hidden layer, use 1/2 of 1st hidden layer
              activation = 'relu') %>%          # use a rectified linear unit as an activation function in 2nd hidden layer
  layer_dropout(rate = 0.2) %>%                 # add dropout with rate 20%
  
  layer_dense(units = output_shape) %>%         # adds an output layer to the network
  layer_activation('softmax')                   # use softmax activation function in the output layer

# compile model
model2 %>% compile(
  optimizer = 'adam',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy')
)

# fit model
model2 %>%
  fit(x = x_train,   # for the x input we exclude columns 1=sentence.id, and 9771=predicter.presidents.name
      y = y_train,
      epochs = 50,
      batch_size = 32,
      validation_data = list(x_test, y_test)) %>%
  plot()
```

```{r}
cat("Train classification success rate = ", mean(model2$predict_classes(x_train) == predicter_presidents_id[train.index]), "\n")
cat("Test classification success rate = ", mean(model2$predict_classes(x_test) == predicter_presidents_id[-train.index]))
```

We can see our test accuracy improved from 48.2% to 54.1%, but the model is still overfitting.

We can also look at the confusion matrix:

```{r}
table(predicted = model2$predict_classes(x_test), actual = predicter_presidents_id[-train.index])
```

This table shows that, for:

* deKlerk (ID = 0), not a single prediction was correct. This can be expected as we had the least number of words for deKlerk (only 1% of all words were assosiated with him).
* Ramaphosa (ID = 5), only 2 predictions were correct. This is also expected as only 2.9% of all words were assosiated with him.
* Zuma (ID = 4), where we had most predictions correct and we also had 30.9% of all words assosiated with him.
* Mbeki (ID = 2), for whom we had the highest word percentage assosiation (39.1%) and where more than half of the predictions where correct.

```{r}
save_model_hdf5(model2, "Waldo_SONA_model2.h5") #save model to use later on
save_model_weights_hdf5(model2, "Waldo_SONA_model2_weights.h5") #save model weights to use later on
```

Let's see if we can get an improvement, by correcting the class imbalance.

```{r}
# initiate model
model3 = keras_model_sequential()

# define model layers
model3 %>% 
  layer_dense(units = 6517,                     # number of neurons in 1st hidden layer, use 2/30 of (input_shape + output_shape)
              activation = 'relu',              # use a rectified linear unit as an activation function in 1st hidden layer
              input_shape = input_shape) %>%    # dimension of input array
  layer_dropout(rate = 0.3) %>%                 # add dropout with rate 30%
  
  layer_dense(units = 3258,                     # number of neurons in 2nd hidden layer, use 1/2 of 1st hidden layer
              activation = 'relu') %>%          # use a rectified linear unit as an activation function in 2nd hidden layer
  layer_dropout(rate = 0.2) %>%                 # add dropout with rate 20%
  
  layer_dense(units = output_shape) %>%         # adds an output layer to the network
  layer_activation('softmax')                   # use softmax activation function in the output layer

# compile model
model3 %>% compile(
  optimizer = 'adam',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy')
)

# fit model
model3 %>%
  fit(x = x_train,
      y = y_train,
      class_weight = list("0"=27.3, "1"=1.6, "2"=1.1, "3"=10, "4"=1, "5"=11.2), # balance classes
      epochs = 50,
      batch_size = 32,
      validation_data = list(x_test, y_test)) %>%
  plot()
```

```{r}
cat("Train classification success rate = ", mean(model3$predict_classes(x_train) == predicter_presidents_id[train.index]), "\n")
cat("Test classification success rate = ", mean(model3$predict_classes(x_test) == predicter_presidents_id[-train.index]))
```

Note out performance is now lower as used less units in the layers.


```{r}
table(predicted = model3$predict_classes(x_test), actual = predicter_presidents_id[-train.index])
```


```{r}
save_model_hdf5(model3, "Waldo_SONA_model3.h5") #save model to use later on
save_model_weights_hdf5(model3, "Waldo_SONA_model3_weights.h5") #save model weights to use later on
```

```{r}
# get sentance summary (with stop words)
sona_sentance_summary_with_stop_words = sona_sentences %>%
  unnest_tokens(word, sentence, token = "words") %>%
  group_by(sentence.id, word) %>%
  summarise(count = n()) %>%
  group_by(sentence.id) %>%
  summarise(words = sum(count)) %>%
  arrange(desc(words))

sona_sentance_summary_with_stop_words %>%
  summarise(Total_sentance = n(),
            Longest_sentance = max(words),
            Average_sentance = mean(words),
            Shortest_sentance = min(words)) %>%
  select(Total_sentance, Longest_sentance, Average_sentance, Shortest_sentance)
```

```{r}
# view sentances which contain 2 or less words (when stop words are included)
sona_sentences %>%
  left_join(sona_sentance_summary_with_stop_words, by = "sentence.id") %>%
  filter(words <= 2) %>%
  select(president, year, sentence, words, sentence.id) %>%
  arrange(words, sentence.id)
```


```{r}
# get sentance summary (without stop words)
sona_sentance_summary_without_stop_words = sona_words %>%
  group_by(sentence.id) %>%
  summarise(words = sum(count)) %>%
  arrange(desc(words))

sona_sentance_summary_without_stop_words %>%
  summarise(Total_sentance = n(),
            Longest_sentance = max(words),
            Average_sentance = mean(words),
            Shortest_sentance = min(words)) %>%
  select(Total_sentance, Longest_sentance, Average_sentance, Shortest_sentance)
```

```{r}
# view sentance which contain 2 or less words (when stop words are removed)
sona_sentences %>%
  left_join(sona_sentance_summary_without_stop_words, by = "sentence.id") %>%
  filter(words <= 2) %>%
  select(president, year, sentence, words, sentence.id) %>%
  arrange(words, sentence.id)
```


## CNN with embeddings

```{r}
max_features = 2000       # choose max_features most popular words
minlen = 5                # exclude sentences shorter than this
maxlen = 75               # longest sentence (for padding)
embedding_dims = 10       # number of dimensions for word embedding

# use Keras to tokenize the sentences
tokenizer = text_tokenizer(num_words = max_features)
fit_text_tokenizer(tokenizer, sona_sentences$sentence)
sequences = tokenizer$texts_to_sequences(sona_sentences$sentence)

# remove sentences shorter than minlen
seq_index = unlist(lapply(sequences, length)) > minlen

# exclude short sequences
lengthIs = function(n) function(x) length(x) > n
sequences = Filter(lengthIs(minlen), sequences)

# get y predicter
predicter_presidents_name_cnn = sona_sentences$president[seq_index]
predicter_presidents_id_cnn = (0:5)[ match(predicter_presidents_name_cnn, c("deKlerk", "Mandela", "Mbeki", "Motlanthe", "Zuma", "Ramaphosa") ) ] 

# build train and test set
train_cnn = list()
test_cnn = list()

train.index.cnn = sample(1:length(sequences),
                         size = 0.8 * length(sequences),
                         replace = F)

train_cnn$x = sequences[train.index.cnn]
test_cnn$x =  sequences[-train.index.cnn]

train_cnn$y = predicter_presidents_id_cnn[train.index.cnn]
test_cnn$y =  predicter_presidents_id_cnn[-train.index.cnn]

# padd shorter sequences with zeros
x_train_cnn = train_cnn$x %>% pad_sequences(maxlen = maxlen)
x_test_cnn = test_cnn$x %>% pad_sequences(maxlen = maxlen)

# one hot encoding
y_train_cnn = to_categorical(train_cnn$y)
y_test_cnn = to_categorical(test_cnn$y)

# initiate model
model4 = keras_model_sequential()

# define model layers
model4 %>% 
  # embedding layer maps vocab indices into embedding_dims dimensions
  layer_embedding(max_features, embedding_dims, input_length = maxlen) %>%
  
  # add some dropout
  layer_dropout(0.2) %>%
  
  # convolutional layer
  layer_conv_1d(
    filters = 250,
    kernel_size = 3, 
    padding = 'valid',  # "valid" means no padding, as we did it already
    activation = 'relu', 
    strides = 1
  ) %>%

  layer_global_max_pooling_1d() %>%
  
  layer_dense(units = 128,
              activation = 'relu') %>%
  layer_dropout(0.2) %>%

  layer_dense(units = output_shape) %>%
  layer_activation('softmax')

# compile model
model4 %>% compile(
  optimizer = 'adam',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy')
)

# fit model
model4 %>%
  fit(x = x_train_cnn,   # for the x input we exclude columns 1=sentence.id, and 9771=predicter.presidents.name
      y = y_train_cnn,
      class_weight = list("0"=27.3, "1"=1.6, "2"=1.1, "3"=10, "4"=1, "5"=11.2),
      epochs = 50,
      batch_size = 32,
      validation_data = list(x_test_cnn, y_test_cnn)) %>%
  plot()
```

```{r}
save_model_hdf5(model4, "Waldo_SONA_model4.h5") #save model to use later on
save_model_weights_hdf5(model4, "Waldo_SONA_model4_weights.h5") #save model weights to use later on
```

```{r}
cat("Train classification success rate = ", mean(model4$predict_classes(x_train_cnn) == train_cnn$y), "\n")
cat("Test classification success rate = ", mean(model4$predict_classes(x_test_cnn) == test_cnn$y))
```

Model 4 is a good improvement on the previous models. We now have an accuracy of 57.6% where the previous best was 54.1%


Let's see if we can improve by using more features and increasing the max length of sentences?

```{r}
max_features = 4000       # choose max_features most popular words
minlen = 5                # exclude sentences shorter than this
maxlen = 125              # longest sentence (for padding)
embedding_dims = 10       # number of dimensions for word embedding

# use Keras to tokenize the sentences
tokenizer = text_tokenizer(num_words = max_features)
fit_text_tokenizer(tokenizer, sona_sentences$sentence)
sequences = tokenizer$texts_to_sequences(sona_sentences$sentence)

# remove sentences shorter than minlen
seq_index = unlist(lapply(sequences, length)) > minlen

# exclude short sequences
lengthIs = function(n) function(x) length(x) > n
sequences = Filter(lengthIs(minlen), sequences)

# get y predicter
predicter_presidents_name_cnn = sona_sentences$president[seq_index]
predicter_presidents_id_cnn = (0:5)[ match(predicter_presidents_name_cnn, c("deKlerk", "Mandela", "Mbeki", "Motlanthe", "Zuma", "Ramaphosa") ) ] 

# build train and test set
train_cnn = list()
test_cnn = list()

train.index.cnn = sample(1:length(sequences),
                         size = 0.8 * length(sequences),
                         replace = F)

train_cnn$x = sequences[train.index.cnn]
test_cnn$x =  sequences[-train.index.cnn]

train_cnn$y = predicter_presidents_id_cnn[train.index.cnn]
test_cnn$y =  predicter_presidents_id_cnn[-train.index.cnn]

# padd shorter sequences with zeros
x_train_cnn = train_cnn$x %>% pad_sequences(maxlen = maxlen)
x_test_cnn = test_cnn$x %>% pad_sequences(maxlen = maxlen)

# one hot encoding
y_train_cnn = to_categorical(train_cnn$y)
y_test_cnn = to_categorical(test_cnn$y)

# initiate model
model5 = keras_model_sequential()

# define model layers
model5 %>% 
  # embedding layer maps vocab indices into embedding_dims dimensions
  layer_embedding(max_features, embedding_dims, input_length = maxlen) %>%
  
  # add some dropout
  layer_dropout(0.2) %>%
  
  # convolutional layer
  layer_conv_1d(
    filters = 250,
    kernel_size = 3, 
    padding = 'valid',  # "valid" means no padding, as we did it already
    activation = 'relu', 
    strides = 1
  ) %>%

  layer_global_max_pooling_1d() %>%
  
  layer_dense(units = 128,
              activation = 'relu') %>%
  layer_dropout(0.2) %>%

  layer_dense(units = output_shape) %>%
  layer_activation('softmax')

# compile model
model5 %>% compile(
  optimizer = 'adam',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy')
)

# fit model
model5 %>%
  fit(x = x_train_cnn,   # for the x input we exclude columns 1=sentence.id, and 9771=predicter.presidents.name
      y = y_train_cnn,
      class_weight = list("0"=27.3, "1"=1.6, "2"=1.1, "3"=10, "4"=1, "5"=11.2),
      epochs = 50,
      batch_size = 32,
      validation_data = list(x_test_cnn, y_test_cnn)) %>%
  plot()
```

```{r}
save_model_hdf5(model5, "Waldo_SONA_model5.h5") #save model to use later on
save_model_weights_hdf5(model5, "Waldo_SONA_model5_weights.h5") #save model weights to use later on
```

```{r}
cat("Train classification success rate = ", mean(model5$predict_classes(x_train_cnn) == train_cnn$y), "\n")
cat("Test classification success rate = ", mean(model5$predict_classes(x_test_cnn) == test_cnn$y))
```

The outcome is not better, which means it is better to have a more general model.

```{r}
max_features = 2000       # choose max_features most popular words
minlen = 5                # exclude sentences shorter than this
maxlen = 75               # longest sentence (for padding)
embedding_dims = 30       # number of dimensions for word embedding

# use Keras to tokenize the sentences
tokenizer = text_tokenizer(num_words = max_features)
fit_text_tokenizer(tokenizer, sona_sentences$sentence)
sequences = tokenizer$texts_to_sequences(sona_sentences$sentence)

# remove sentences shorter than minlen
seq_index = unlist(lapply(sequences, length)) > minlen

# exclude short sequences
lengthIs = function(n) function(x) length(x) > n
sequences = Filter(lengthIs(minlen), sequences)

# get y predicter
predicter_presidents_name_cnn = sona_sentences$president[seq_index]
predicter_presidents_id_cnn = (0:5)[ match(predicter_presidents_name_cnn, c("deKlerk", "Mandela", "Mbeki", "Motlanthe", "Zuma", "Ramaphosa") ) ] 

# build train and test set
train_cnn = list()
test_cnn = list()

train.index.cnn = sample(1:length(sequences),
                         size = 0.8 * length(sequences),
                         replace = F)

train_cnn$x = sequences[train.index.cnn]
test_cnn$x =  sequences[-train.index.cnn]

train_cnn$y = predicter_presidents_id_cnn[train.index.cnn]
test_cnn$y =  predicter_presidents_id_cnn[-train.index.cnn]

# padd shorter sequences with zeros
x_train_cnn = train_cnn$x %>% pad_sequences(maxlen = maxlen)
x_test_cnn = test_cnn$x %>% pad_sequences(maxlen = maxlen)

# one hot encoding
y_train_cnn = to_categorical(train_cnn$y)
y_test_cnn = to_categorical(test_cnn$y)

# initiate model
model6 = keras_model_sequential()

# define model layers
model6 %>% 
  # embedding layer maps vocab indices into embedding_dims dimensions
  layer_embedding(max_features, embedding_dims, input_length = maxlen) %>%
  
  # add some dropout
  layer_dropout(0.2) %>%
  
  # convolutional layer
  layer_conv_1d(
    filters = 250,
    kernel_size = 3, 
    padding = 'valid',  # "valid" means no padding, as we did it already
    activation = 'relu', 
    strides = 1
  ) %>%

  layer_global_max_pooling_1d() %>%
  
  layer_dense(units = 128,
              activation = 'relu') %>%
  layer_dropout(0.2) %>%

  layer_dense(units = output_shape) %>%
  layer_activation('softmax')

# compile model
model6 %>% compile(
  optimizer = 'adam',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy')
)

# fit model
model6 %>%
  fit(x = x_train_cnn,   # for the x input we exclude columns 1=sentence.id, and 9771=predicter.presidents.name
      y = y_train_cnn,
      class_weight = list("0"=27.3, "1"=1.6, "2"=1.1, "3"=10, "4"=1, "5"=11.2),
      epochs = 50,
      batch_size = 32,
      validation_data = list(x_test_cnn, y_test_cnn)) %>%
  plot()
```

```{r}
save_model_hdf5(model6, "Waldo_SONA_model6.h5") #save model to use later on
save_model_weights_hdf5(model6, "Waldo_SONA_model6_weights.h5") #save model weights to use later on
```

```{r}
cat("Train classification success rate = ", mean(model6$predict_classes(x_train_cnn) == train_cnn$y), "\n")
cat("Test classification success rate = ", mean(model6$predict_classes(x_test_cnn) == test_cnn$y))
```